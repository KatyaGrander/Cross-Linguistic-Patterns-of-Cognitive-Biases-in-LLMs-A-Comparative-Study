**Cross-Linguistic Patterns of Cognitive Biases in Large Language Models: A Comparative Study in English, Hebrew, and Russian
**
Large Language Models (LLMs) are being increasingly incorporated into decision-support systems. Nonetheless, a lack of clarity remains with reference to their reasoning processes, particularly in multilingual contexts. This study investigated the ability of three widely used LLMs (ChatGPT, Claude, and Gemini), as well as human control group, to solve cognitive tasks targeting availability heuristics and confirmation bias. The tasks were administered in three different languages – English, Hebrew, and Russian. Statistical analyses compared correctness patterns across models, tasks, and languages, with human performance serving as a baseline. The results revealed a “cognitive gap”: LLMs consistently outperformed human participants on rule-based deductive tasks, yet exhibited bias-mimicking error patterns in heuristic reasoning-based tasks. These bias-replication patterns varied significantly across languages, challenging the expectation of uniform multilingual performance and suggesting that LLM reasoning interacts with linguistic structures in unpredictable ways. The study findings demonstrate that cognitive bias expression in LLM outputs is not merely a technical constraint but a language-dependent phenomenon with practical implications for deployment in multilingual environments, emphasizing the importance of cross-linguistic evaluation when assessing the reliability of AI systems.
